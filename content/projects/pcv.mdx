---
title: Interactive 'Higher or Lower' Game
description: An interactive “Higher or Lower” game that uses real time computer vision to turn physical playing cards into game controllers. By recognizing cards directly from a webcam feed, the system replaces traditional keyboard input with a more natural, hands-on way to play.
teaser: "OpenCV real-time card recognition"
date: "2025-01-15"
published: true
repository: 
tags:
  - "Computer Vision"
  - "Python"
  - "OpenCV"
  - "Pygame"
status: "Completed"
platform: "IoT"
highlights:
- "Live dashboard"
---

Why limit gaming to a mouse and keyboard? **The Higher or Lower Project** explores the frontier of Human Computer Interaction by turning physical objects into digital inputs.

I engineered this system to "see" and understand a standard deck of cards in real-time. By leveraging lightweight computer vision algorithms, the game detects the rank and suit of a card instantly, creating a seamless bridge between the physical tabletop and the digital screen.

<YouTube id= "xwwmVB0pl1c" />

---

## The Stack

I built this system to be lightweight and efficient, proving that robust object recognition doesn't always require heavy deep learning models.

| Component | Technology | Role |
| :--- | :--- | :--- |
| **Core Logic** | Python | Main application controller |
| **Vision Engine** | OpenCV | Image processing & contour detection |
| **Game Loop** | Pygame | UI rendering & state management |
| **Hardware** | Standard Webcam | Real-time video input |

---

## The Vision Pipeline

The challenge was to make the system robust against lighting changes and card rotation. I implemented a three-stage pipeline:

### 1. Pre-processing (The Filter)
Before the system can "read," it must simplify the world.
* **Grayscale & Blur:** I strip away color and smooth out high-frequency noise using Gaussian Blur.
* **Canny Edge Detection:** The system isolates the card's structure by detecting drastic gradients in pixel intensity, separating the object from the background.

### 2. Homography (The Perspective Fix)
Users rarely hold cards perfectly straight. To solve this, I implemented a **Perspective Transform**.
* The system detects the four corners of the card's contour.
* It calculates a transformation matrix to mathematically "warp" the image.
* **Result:** A perfectly flattened, top-down view of the card, regardless of how the user holds it in 3D space.

### 3. Template Matching (The Brain)
Instead of a heavy Neural Network, I used a highly optimized **Sum of Absolute Differences (SAD)** algorithm.
* The system compares the flattened card against a pre-loaded database of 52 reference images.
* It calculates the pixel difference score for every candidate.
* The lowest score wins—identifying the card with high accuracy in milliseconds.

---

## Game Architecture

The logic is decoupled from the vision system to prevent frame-rate drops.

* **State Machine:** The game cycles through distinct states (`WAITING`, `DETECTED`, `GUESSING`) to ensure inputs are deliberate.
* **Safety Protocols:** I implemented validation checks to prevent the game from crashing if a card is partially obscured or dropped.

```python
if self.current_card is None:
    self.message = "Wait for Reference Card! Press 'R'."
    return False

if self.next_card is None:
    self.message = "Wait for GUESS Card detection!"
    return False